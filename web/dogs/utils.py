import os
import json
import re
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
async_client = AsyncOpenAI(api_key=openai_api_key)

# ê° test_idê°€ ì–´ë–¤ ì„±ê²© ì¶•ì— í•´ë‹¹í•˜ëŠ”ì§€ ì •ì˜
DIMENSION_MAP = {
    1: "E/I", 2: "E/I", 3: "E/I",
    4: "S/N", 5: "S/N", 6: "S/N",
    7: "T/F", 8: "T/F", 9: "T/F",
    10: "J/P", 11: "J/P", 12: "J/P",
}

def extract_json(text: str) -> str:
    """GPT ì‘ë‹µì—ì„œ JSON ë¸”ë¡ë§Œ ì¶”ì¶œ"""
    match = re.search(r'\[?\s*\{.*\}\s*\]?', text, re.DOTALL)
    return match.group(0) if match else "[]"

async def get_test_questions(test_id: int):
    """
    test_idì— ë”°ë¼ GPTì—ê²Œ ì„±ê²© ê²€ì‚¬ ë¬¸í•­ì„ ìƒì„± ìš”ì²­í•˜ê³ ,
    ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ íŒŒì‹±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    dimension = DIMENSION_MAP.get(test_id, "E/I")

    prompt = f"""
ë‹¹ì‹ ì€ ë°˜ë ¤ê²¬ ì„±ê²© ìœ í˜• ê²€ì‚¬ë¥¼ ë§Œë“œëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

ì¡°ê±´:
1. ì„±ê²© ì¶•: {dimension} (ì˜ˆ: E/I, S/N, T/F, J/P)
2. ì§ˆë¬¸ì€ ë°˜ë ¤ê²¬ ë³´í˜¸ìê°€ ê°ê´€ì‹ìœ¼ë¡œ ë‹µí•  ìˆ˜ ìˆëŠ” í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
3. ê° ì§ˆë¬¸ì€ ì„ íƒì§€ 2ê°œë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•˜ë©°, ì„±ê²©ì˜ ì–‘ê·¹ì„ ë‚˜íƒ€ë‚´ì•¼ í•©ë‹ˆë‹¤.
4. ê° ì§ˆë¬¸ì€ ë°˜ë ¤ê²¬ì˜ í–‰ë™ì´ë‚˜ ì„±í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¬»ëŠ” ë‚´ìš©ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
5. ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ JSON ë°°ì—´ë¡œ í•˜ì„¸ìš”:

[
  {{
    "question": "ì‚°ì±…í•  ë•Œ ì–´ë–¤ê°€ìš”?",
    "name": "q{test_id}_1",
    "options": [
      {{"value": "E", "text": "ë‹¤ë¥¸ ê°•ì•„ì§€ë‚˜ ì‚¬ëŒì—ê²Œ ë¨¼ì € ë‹¤ê°€ê°€ìš”"}},
      {{"value": "I", "text": "í˜¼ì ì¡°ìš©íˆ ê±·ëŠ” ê±¸ ì„ í˜¸í•´ìš”"}}
    ]
  }}
]

ì§€ê¸ˆì€ test_id={test_id}ì´ê³ , ì£¼ì œ ì„±ê²© ì¶•ì€ {dimension}ì…ë‹ˆë‹¤.
ë¬¸í•­ 1ê°œë¥¼ ìœ„ì˜ í˜•ì‹ì²˜ëŸ¼ JSON ë°°ì—´ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
"""

    try:
        response = await async_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë°˜ë ¤ê²¬ ì„±ê²©ê²€ì‚¬ ë¬¸í•­ì„ ë§Œë“œëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )

        raw = response.choices[0].message.content.strip()
        print(f"ğŸ“¥ GPT ì‘ë‹µ (test_id={test_id}):\n{raw}\n")
        json_text = extract_json(raw)
        return json.loads(json_text)

    except Exception as e:
        print("âŒ GPT API ì˜¤ë¥˜:", e)
        return []
    

async def generate_character_from_type(mbti_type: str):
    prompt = f"""
ë‹¹ì‹ ì€ ë°˜ë ¤ê²¬ ì„±ê²© ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì„±ê²© ìœ í˜• {mbti_type}ì— í•´ë‹¹í•˜ëŠ” ê°•ì•„ì§€ì˜ ì„±ê²©ì„ ë³´í˜¸ìì—ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì¡°ê±´:
1. ì„¤ëª…ì€ ë°˜ë ¤ê²¬ ì…ì¥ì—ì„œ 2~3ë¬¸ì¥ ì •ë„ë¡œ ì§§ê²Œ í•´ì£¼ì„¸ìš”. (ex. "ë‚˜ëŠ” ë‚¯ì„  ì‚¬ëŒë³´ë‹¤ í˜¼ì ìˆëŠ” ê±¸ ë” ì¢‹ì•„í•´ìš”!")
2. ë„ˆë¬´ ì „ë¬¸ ìš©ì–´ ë§ê³  ë”°ëœ»í•˜ê³  ê·€ì—¬ìš´ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
3. ë§ˆì§€ë§‰ì— ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ #í•´ì‹œíƒœê·¸ 3ê°œë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:
{{
  "type": "INFP",
  "character": "ë‚˜ëŠ” ë‚¯ì„  í™˜ê²½ì—ì„  ì¡°ì‹¬ìŠ¤ëŸ½ì§€ë§Œ, ìµìˆ™í•´ì§€ë©´ ë³´í˜¸ìì—ê²Œ ë¬´í•œ ì• ì •ì„ í‘œí˜„í•´ìš”!",
  "hashtags": ["#ì†Œì‹¬í•˜ì§€ë§Œì‚¬ë‘ìŠ¤ëŸ¬ì›€", "#í˜¼ìë†€ê¸°ì¥ì¸", "#ë§ˆìŒì—¬ë¦°ê°•ì•„ì§€"]
}}
"""

    try:
        response = await async_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë°˜ë ¤ê²¬ ì„±ê²© ë¶„ì„ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )

        raw = response.choices[0].message.content.strip()
        print(f"ğŸ“¥ GPT ì‘ë‹µ (MBTI={mbti_type}):\n{raw}\n")
        json_text = extract_json(raw)
        return json.loads(json_text)

    except Exception as e:
        print("âŒ GPT ì‘ë‹µ ì˜¤ë¥˜:", e)
        return {
            "type": mbti_type,
            "character": "ì„¤ëª… ìƒì„± ì‹¤íŒ¨ ğŸ˜¥",
            "hashtags": []
        }
